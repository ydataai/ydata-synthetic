# Importing necessary libraries and modules
import json
import pandas as pd

# Defining the name of the dataset
dataset_name = "BankChurn"

# Reading the real dataset from a CSV file
real = pd.read_csv('BankChurners.csv')

# Reading the synthetic dataset from a CSV file
synth = pd.read_csv(f'synth_{dataset_name}', index_col=0)

# Reading the JSON profiling report of the real dataset
f = open(f'.profile_{dataset_name}.json')
json_profile = json.load(f)
json_profile = json.loads(json_profile)

# Profiling the synthetic dataset using pandas_profiling
from pandas_profiling import ProfileReport
title = f"Synth: {dataset_name}"
synth_profile = ProfileReport(synth, title=title)
synth_profile.to_file('synth_profile.html')

# Loading the expectation suite for the real dataset
import great_expectations as ge
data_context = ge.data_context.DataContext(context_root_dir="great_expectations")
suite = data_context.get_expectation_suite(f"{dataset_name}_expectations")

# Creating a PandasDataset object for the synthetic dataset
batch = ge.dataset.PandasDataset(synth, expectation_suite=suite)

# Running the expectations and getting the validation result identifier
results = data_context.run_validation_operator(
    "action_list_operator", assets_to_validate=[batch]
)
validation_result_identifier = results.list_validation_result_identifiers()[0]

# Building and opening the Data Docs for the synthetic dataset
data_context.build_data_docs()
data_context.open_data_docs(validation_result_identifier)
