{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gumbel-Softmax - New feature\n",
    "This notebook showcases a new feature introduced in version 0.6, Gumbel-Softmax activations!\n",
    "\n",
    "**Structure of the notebook:**\n",
    "\n",
    "1. A quick recap on categorical feature synthesis\n",
    "2. Softmax and the Gumbel-Softmax activation\n",
    "3. Synthesized categorical features comparison\n",
    "    * Previous version\n",
    "    * New version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick recap on categorical feature synthesis\n",
    "Before synthesizing we typically preprocess our features. In the case of categorical features, one-hot encodings are frequently used in order to transform discrete features into sparse blocks of 1's and 0's. Converting symbolic inputs like categorical features to sparse arrays allows neural network (NN) models to handle the data similarly to very different feature formats like numerical continuous features.\n",
    "\n",
    "An example:\n",
    "* Before one-hot encoding:\n",
    "\n",
    "<style>\n",
    "th {\n",
    "  padding-top: 5px;\n",
    "  padding-right: 10px;\n",
    "  padding-bottom: 5px;\n",
    "  padding-left: 10px;\n",
    "}\n",
    "</style>\n",
    "\n",
    "| ID | Gender | AgeRange |\n",
    "| :------------: | :-------:  | :-------:  |\n",
    "| 1 | Male | 20-29 |\n",
    "| 2 | Female | 10-19 |\n",
    "\n",
    "* After one-hot encoding:\n",
    "\n",
    "| ID | Gender_Male | Gender_Female | AgeRange_10-19 | AgeRange_20-29 |\n",
    "| :------------: | :-------:  | :-------:  | :-------:  | :-------:  |\n",
    "| 1 | 1 | 0 | 0 | 1 |\n",
    "| 2 | 0 | 1 | 1 | 0 |\n",
    "\n",
    "GANs attempt to synthesize these sparse distributions as they appear on real data. However, despite the input categorical features having a sparse format, NN classifiers learn __[logits](https://en.wikipedia.org/wiki/Logit)__, non-normalized probability distributions, for each class represented in the one-hot encoded input. Without activation layers that can handle this output, you might get synthetic records looking something like this:\n",
    "\n",
    "| ID | Gender_Male | Gender_Female | AgeRange_10-19 | AgeRange_20-29 |\n",
    "| :------------: | :-------:  | :-------:  | :-------:  | :-------:  |\n",
    "| 1 | 0.867 | 0.622 | -0.155 | 0.855 |\n",
    "| 2 | 0.032 | 1.045 | 0.901 | -0.122 |\n",
    "\n",
    "This looks messy; leaves you with the job of inferring a sensible output (p.e. use the class with highest activation) and also is a potential flag for a GAN discriminator to identify fake samples.\n",
    "\n",
    "Let's see what Gumbel-Softmax is and what it can do about to fix the issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax and the Gumbel-Softmax activation\n",
    "Softmax is a differentiable family of functions that map an array of logits to probabilities, i.e. values are bounded in the range $[0, 1]$ and sum to 1.\n",
    "These are often used for turning logits into probability distributions from which we can sample. However these samples can't help us in gradient descent model learning because they are obtained from a random process (no relation with the model's parameters).\n",
    "\n",
    "The Gumbel-Softmax (GS) is a special kind of Softmax function that got introduced in 2016 (fun fact: coincidentally it was proposed in the same time by two independent teams) __[\\[1](https://arxiv.org/abs/1611.00712)__, __[2\\]](https://arxiv.org/abs/1611.00712)__. It works like a continuous approximation of Softmax. Instead of using logits directly __[Gumbel distribution](https://en.wikipedia.org/wiki/Gumbel_distribution)__ noise is added before the softmax operation so that our model is outputting a combination from a deterministic component, parameterized by the mean and the variance of the categorical distribution, and a stochastic component, the Gumbel noise, which is just helping us sample without adding bias to the process.\n",
    "\n",
    "A temperature parameter, usually called tau or lambda and defined in $]0, inf[$ is used to tune this distribution between the true categorical distribution and a uniform distribution respectively. This parameter is usually kept close to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesized categorical features comparison\n",
    "To showcase the new feature we will focus on the visual inspection of the categorical outputs, similar to the examples above.\n",
    "For this comparison we will leverage the DRAGAN implementation of the library on the adult dataset. The available snippets should reproduce the results but the takeaways are fully delivered on the cached results of this notebook.\n",
    "Since the new feature is already implemented in our DRAGAN implementation, we will inherit and make a very simple override so that we use a generator without the GS activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data\n",
    "\n",
    "from ydata_synthetic.synthesizers.regular import DRAGAN\n",
    "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
    "\n",
    "data = fetch_data('adult')\n",
    "num_cols = ['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_cols = ['workclass','education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "            'native-country', 'target']\n",
    "\n",
    "\n",
    "# DRAGAN training\n",
    "#Defining the training parameters of DRAGAN\n",
    "\n",
    "noise_dim = 128\n",
    "dim = 128\n",
    "batch_size = 500\n",
    "\n",
    "log_step = 100\n",
    "epochs = 5  # For the purpose of this demo the number of epochs does not really matter, we are just comparing output formats\n",
    "learning_rate = 1e-5\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.9\n",
    "\n",
    "gan_args = ModelParameters(batch_size=batch_size,\n",
    "                           lr=learning_rate,\n",
    "                           betas=(beta_1, beta_2),\n",
    "                           noise_dim=noise_dim,\n",
    "                           layers_dim=dim)\n",
    "\n",
    "train_args = TrainParameters(epochs=epochs,\n",
    "                             sample_interval=log_step)\n",
    "\n",
    "n_discriminator = 3\n",
    "sample_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mimicking the previous DRAGAN implementation\n",
    "class OldDRAGAN(DRAGAN):\n",
    "    \"\"\"The simple override of the define_gan below blocks the generator from plugging in the GS activation layer.\n",
    "    This makes it equivalent to the previous implementation.\n",
    "    The source code will help you understanding how it works\"\"\"\n",
    "    def define_gan(self, col_transform_info = None):\n",
    "        super().define_gan(col_transform_info=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous DRAGAN version synthesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:10<00:42, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | disc_loss: -0.36303991079330444 | gen_loss: -0.02544642798602581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:20<00:31, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | disc_loss: -0.5309355854988098 | gen_loss: -0.020024392753839493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:31<00:20, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | disc_loss: -0.4962470829486847 | gen_loss: -0.04659884423017502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:41<00:10, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | disc_loss: -0.34895461797714233 | gen_loss: -0.09296654164791107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:52<00:00, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | disc_loss: -0.0004760622978210449 | gen_loss: -0.2121104896068573\n",
      "New DRAGAN version synthesis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [00:14<00:59, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | disc_loss: -0.2968001067638397 | gen_loss: -0.16787190735340118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:30<00:45, 15.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | disc_loss: -0.4475342333316803 | gen_loss: -0.08200405538082123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:44<00:29, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | disc_loss: -0.5292890667915344 | gen_loss: -0.06154463812708855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:58<00:14, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | disc_loss: -0.6085172891616821 | gen_loss: -0.05449139326810837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:13<00:00, 14.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | disc_loss: -0.632192850112915 | gen_loss: -0.03990979120135307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Synthetic data generation: 100%|██████████| 1/1 [00:00<00:00, 95.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.random import uniform\n",
    "from tensorflow.dtypes import float32\n",
    "\n",
    "# Random noise for sampling both generators\n",
    "noise = uniform([sample_size, noise_dim], dtype=float32)\n",
    "\n",
    "print('Previous DRAGAN version synthesis')\n",
    "old_dragan = OldDRAGAN(gan_args, n_discriminator)\n",
    "old_dragan.train(data, train_args, num_cols, cat_cols)\n",
    "\n",
    "old_samples = old_dragan.generator(noise, training=False).numpy()\n",
    "\n",
    "print('New DRAGAN version synthesis')\n",
    "new_dragan = DRAGAN(gan_args, n_discriminator)\n",
    "new_dragan.train(data, train_args, num_cols, cat_cols)\n",
    "\n",
    "new_samples = new_dragan.sample(sample_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample both generators\n",
    "old_samples = old_dragan.generator(noise, training=False).numpy()\n",
    "new_samples = new_dragan.generator(noise, training=False).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "# Get the input/output data preprocessor map to help us isolate the categorical feats output\n",
    "preprocessor_map = new_dragan.processor.col_transform_info\n",
    "\n",
    "# Isolate the categorical features and get the feature names\n",
    "n_num_feats = len(preprocessor_map.numerical.feat_names_in)\n",
    "cat_out_names = preprocessor_map.categorical.feat_names_out\n",
    "\n",
    "# Place the categorical parts of the samples in Pandas DataFrames\n",
    "old_cat_samples = DataFrame(old_samples[:,n_num_feats:], columns=cat_out_names)\n",
    "new_cat_samples = DataFrame(new_samples[:,n_num_feats:], columns=cat_out_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_0</th>\n",
       "      <th>workclass_1</th>\n",
       "      <th>workclass_2</th>\n",
       "      <th>workclass_3</th>\n",
       "      <th>workclass_4</th>\n",
       "      <th>workclass_5</th>\n",
       "      <th>workclass_6</th>\n",
       "      <th>workclass_7</th>\n",
       "      <th>workclass_8</th>\n",
       "      <th>education_0</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_34</th>\n",
       "      <th>native-country_35</th>\n",
       "      <th>native-country_36</th>\n",
       "      <th>native-country_37</th>\n",
       "      <th>native-country_38</th>\n",
       "      <th>native-country_39</th>\n",
       "      <th>native-country_40</th>\n",
       "      <th>native-country_41</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401984</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.624994</td>\n",
       "      <td>0.195168</td>\n",
       "      <td>1.291041</td>\n",
       "      <td>1.116580</td>\n",
       "      <td>-0.820349</td>\n",
       "      <td>1.031810</td>\n",
       "      <td>-0.309409</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324346</td>\n",
       "      <td>-0.971263</td>\n",
       "      <td>-0.089323</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>-0.646701</td>\n",
       "      <td>1.144929</td>\n",
       "      <td>-1.546669</td>\n",
       "      <td>-0.374628</td>\n",
       "      <td>1.099963</td>\n",
       "      <td>1.221397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.048472</td>\n",
       "      <td>0.215874</td>\n",
       "      <td>0.414385</td>\n",
       "      <td>0.116093</td>\n",
       "      <td>1.136396</td>\n",
       "      <td>0.920146</td>\n",
       "      <td>-0.329587</td>\n",
       "      <td>1.086331</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>1.351759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.249410</td>\n",
       "      <td>-0.225080</td>\n",
       "      <td>-0.025395</td>\n",
       "      <td>0.351308</td>\n",
       "      <td>-0.826858</td>\n",
       "      <td>1.029490</td>\n",
       "      <td>-0.388164</td>\n",
       "      <td>-0.265167</td>\n",
       "      <td>0.755968</td>\n",
       "      <td>1.115297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119381</td>\n",
       "      <td>0.338525</td>\n",
       "      <td>0.518873</td>\n",
       "      <td>0.783457</td>\n",
       "      <td>1.573044</td>\n",
       "      <td>0.659619</td>\n",
       "      <td>-0.732085</td>\n",
       "      <td>1.006257</td>\n",
       "      <td>0.063389</td>\n",
       "      <td>1.217871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082185</td>\n",
       "      <td>-0.571648</td>\n",
       "      <td>-0.377966</td>\n",
       "      <td>0.536919</td>\n",
       "      <td>-0.731658</td>\n",
       "      <td>0.955397</td>\n",
       "      <td>-0.601435</td>\n",
       "      <td>0.502624</td>\n",
       "      <td>0.996215</td>\n",
       "      <td>1.403981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594597</td>\n",
       "      <td>0.159835</td>\n",
       "      <td>0.392797</td>\n",
       "      <td>0.160737</td>\n",
       "      <td>1.216151</td>\n",
       "      <td>0.614027</td>\n",
       "      <td>-0.298966</td>\n",
       "      <td>0.824552</td>\n",
       "      <td>-0.886809</td>\n",
       "      <td>1.000056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007130</td>\n",
       "      <td>-0.033384</td>\n",
       "      <td>-0.287456</td>\n",
       "      <td>0.433346</td>\n",
       "      <td>-0.681390</td>\n",
       "      <td>1.312952</td>\n",
       "      <td>-1.376490</td>\n",
       "      <td>0.169668</td>\n",
       "      <td>0.686038</td>\n",
       "      <td>1.332423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.244797</td>\n",
       "      <td>0.546484</td>\n",
       "      <td>0.676641</td>\n",
       "      <td>0.050418</td>\n",
       "      <td>1.352613</td>\n",
       "      <td>0.527226</td>\n",
       "      <td>-0.750618</td>\n",
       "      <td>0.742486</td>\n",
       "      <td>0.062396</td>\n",
       "      <td>1.068858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248066</td>\n",
       "      <td>-0.679454</td>\n",
       "      <td>-0.210461</td>\n",
       "      <td>0.603596</td>\n",
       "      <td>-0.296030</td>\n",
       "      <td>0.873734</td>\n",
       "      <td>-0.138126</td>\n",
       "      <td>0.413228</td>\n",
       "      <td>0.388745</td>\n",
       "      <td>1.675902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_0  workclass_1  workclass_2  workclass_3  workclass_4  \\\n",
       "0     0.401984     0.006191     0.624994     0.195168     1.291041   \n",
       "1    -0.048472     0.215874     0.414385     0.116093     1.136396   \n",
       "2     0.119381     0.338525     0.518873     0.783457     1.573044   \n",
       "3     0.594597     0.159835     0.392797     0.160737     1.216151   \n",
       "4     0.244797     0.546484     0.676641     0.050418     1.352613   \n",
       "\n",
       "   workclass_5  workclass_6  workclass_7  workclass_8  education_0  ...  \\\n",
       "0     1.116580    -0.820349     1.031810    -0.309409     0.915270  ...   \n",
       "1     0.920146    -0.329587     1.086331     0.065789     1.351759  ...   \n",
       "2     0.659619    -0.732085     1.006257     0.063389     1.217871  ...   \n",
       "3     0.614027    -0.298966     0.824552    -0.886809     1.000056  ...   \n",
       "4     0.527226    -0.750618     0.742486     0.062396     1.068858  ...   \n",
       "\n",
       "   native-country_34  native-country_35  native-country_36  native-country_37  \\\n",
       "0           0.324346          -0.971263          -0.089323           0.457682   \n",
       "1          -0.249410          -0.225080          -0.025395           0.351308   \n",
       "2          -0.082185          -0.571648          -0.377966           0.536919   \n",
       "3           0.007130          -0.033384          -0.287456           0.433346   \n",
       "4          -0.248066          -0.679454          -0.210461           0.603596   \n",
       "\n",
       "   native-country_38  native-country_39  native-country_40  native-country_41  \\\n",
       "0          -0.646701           1.144929          -1.546669          -0.374628   \n",
       "1          -0.826858           1.029490          -0.388164          -0.265167   \n",
       "2          -0.731658           0.955397          -0.601435           0.502624   \n",
       "3          -0.681390           1.312952          -1.376490           0.169668   \n",
       "4          -0.296030           0.873734          -0.138126           0.413228   \n",
       "\n",
       "   target_0  target_1  \n",
       "0  1.099963  1.221397  \n",
       "1  0.755968  1.115297  \n",
       "2  0.996215  1.403981  \n",
       "3  0.686038  1.332423  \n",
       "4  0.388745  1.675902  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the old categorical outputs of the generator\n",
    "old_cat_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass_0</th>\n",
       "      <th>workclass_1</th>\n",
       "      <th>workclass_2</th>\n",
       "      <th>workclass_3</th>\n",
       "      <th>workclass_4</th>\n",
       "      <th>workclass_5</th>\n",
       "      <th>workclass_6</th>\n",
       "      <th>workclass_7</th>\n",
       "      <th>workclass_8</th>\n",
       "      <th>education_0</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_34</th>\n",
       "      <th>native-country_35</th>\n",
       "      <th>native-country_36</th>\n",
       "      <th>native-country_37</th>\n",
       "      <th>native-country_38</th>\n",
       "      <th>native-country_39</th>\n",
       "      <th>native-country_40</th>\n",
       "      <th>native-country_41</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   workclass_0  workclass_1  workclass_2  workclass_3  workclass_4  \\\n",
       "0          0.0          0.0          1.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          1.0          0.0   \n",
       "\n",
       "   workclass_5  workclass_6  workclass_7  workclass_8  education_0  ...  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "1          0.0          1.0          0.0          0.0          0.0  ...   \n",
       "2          0.0          0.0          1.0          0.0          0.0  ...   \n",
       "3          0.0          0.0          1.0          0.0          0.0  ...   \n",
       "4          0.0          0.0          0.0          0.0          0.0  ...   \n",
       "\n",
       "   native-country_34  native-country_35  native-country_36  native-country_37  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   native-country_38  native-country_39  native-country_40  native-country_41  \\\n",
       "0                0.0                0.0                0.0                1.0   \n",
       "1                0.0                0.0                1.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                1.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   target_0  target_1  \n",
       "0       1.0       0.0  \n",
       "1       1.0       0.0  \n",
       "2       0.0       1.0  \n",
       "3       1.0       0.0  \n",
       "4       0.0       1.0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the new categorical outputs of the generator\n",
    "new_cat_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice the difference of the Gumbel-Softmax in the output of the generators?\n",
    "By default this feature is implemented in all the regular generators.\n",
    "\n",
    "Enjoy the improved categorical generation!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98ab1d40448dd008ad1b7decdd6b8b1a271c78de377aef983939bf1a8fd37a83"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ydata_synth': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
