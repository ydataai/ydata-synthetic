{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "AnCU8-Mal4fV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# The Credit Card Fraud Dataset - Synthesizing the Minority Class\n",
    "\n",
    "In this notebook a practical exercise is presented to showcase the usage of the YData Synthetic library along with\n",
    "GANs to synthesize tabular data.\n",
    "For the purpose of this exercise, dataset of credit card fraud from Kaggle is used, that can be found here:\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j0CX0r65l4fY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Note: You can select between running the Notebook on \"CPU\" or \"GPU\"\n",
    "# Click \"Runtime > Change Runtime time\" and set \"GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "id": "x0u2qegKl4fY",
    "outputId": "51b00474-09de-4e9a-dbf9-9535f056fbd0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install ydata-synthetic lib\n",
    "# ! pip install ydata-synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oX2OK2fbl4fZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.cluster as cluster\n",
    "from numpy import array, random, sum, unique\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
    "from ydata_synthetic.synthesizers.regular import VanilllaGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P1Rcz4RPl4fZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = VanilllaGAN\n",
    "\n",
    "# Read the original data and have it preprocessed\n",
    "data = read_csv('../../data/creditcard.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceNe1Ofbl4fZ",
    "outputId": "f8f9fece-e7d3-454f-d4c9-d6cd116ca68a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n"
     ]
    }
   ],
   "source": [
    "#List of columns different from the Class column\n",
    "num_cols = list(data.columns[ data.columns != 'Class' ])\n",
    "cat_cols = ['Class']\n",
    "\n",
    "print('Dataset columns: {}'.format(num_cols))\n",
    "sorted_cols = ['V14', 'V4', 'V10', 'V17', 'V12', 'V26', 'Amount', 'V21', 'V8', 'V11', 'V7', 'V28', 'V19', 'V3', 'V22', 'V6', 'V20', 'V27', 'V16', 'V13', 'V25', 'V24', 'V18', 'V2', 'V1', 'V5', 'V15', 'V9', 'V23', 'Class']\n",
    "processed_data = data[ sorted_cols ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3o4V8-ypl4fa",
    "outputId": "39fabdb7-b3e4-492f-85f0-cd6232b45609",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info: Number of records - 492 Number of variables - 30\n",
      "   count\n",
      "0    455\n",
      "1     37\n"
     ]
    }
   ],
   "source": [
    "# For the purpose of this example we will only synthesize the minority class\n",
    "# train_data contains 492 rows which had 'Class' value as 1 (which were very few)\n",
    "train_data = data.loc[ data['Class']==1 ].copy()\n",
    "\n",
    "print(\"Dataset info: Number of records - {} Number of variables - {}\".format(train_data.shape[0], train_data.shape[1]))\n",
    "\n",
    "# We define a K-means clustering method using sklearn, and declare that\n",
    "# we want 2 clusters. We then apply this algorithm (fit_predict) to our train_data\n",
    "# We essentially get an array of 492 rows ('labels') having values either 0 or 1 for the 2 clustered classes.\n",
    "algorithm = cluster.KMeans\n",
    "args, kwds = (), {'n_clusters':2, 'random_state':0}\n",
    "labels = algorithm(*args, **kwds).fit_predict(train_data[ num_cols ])\n",
    "\n",
    "# Get the count of both classes\n",
    "print( DataFrame( [ [sum(labels==i)] for i in unique(labels) ], columns=['count'], index=unique(labels) ) )\n",
    "\n",
    "# Assign the k-means clustered classes' labels to the a seperate copy of train data 'fraud_w_classes'\n",
    "fraud_w_classes = train_data.copy()\n",
    "fraud_w_classes['Class'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ezlIjKbl4fb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# GAN training\n",
    "\n",
    "Below you can try to train your own generators using the available GANs architectures. You can train it either with labels (created using KMeans) or with no labels at all. \n",
    "\n",
    "Remember that for this exercise in particular we've decided to synthesize only the minority class from the Credit Fraud dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7FMDs5eql4fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the GAN and training parameters\n",
    "noise_dim = 32\n",
    "dim = 128\n",
    "batch_size = 128\n",
    "\n",
    "log_step = 100\n",
    "epochs = 200+1\n",
    "learning_rate = 5e-4\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.9\n",
    "models_dir = './cache'\n",
    "\n",
    "#Setting the GAN model parameters and the training step parameters\n",
    "gan_args = ModelParameters(batch_size=batch_size,\n",
    "                           lr=learning_rate,\n",
    "                           betas=(beta_1, beta_2),\n",
    "                           noise_dim=noise_dim,\n",
    "                           layers_dim=dim)\n",
    "\n",
    "train_args = TrainParameters(epochs=epochs,\n",
    "                             sample_interval=log_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgMDmyall4fc",
    "outputId": "ae669bdf-01b6-49d9-a254-cc0776508f7b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/201 [00:00<00:40,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.550036, acc.: 50.00%] [G loss: 0.627987]\n",
      "generated_data\n",
      "1 [D loss: 0.724137, acc.: 50.00%] [G loss: 0.482935]\n",
      "2 [D loss: 0.773580, acc.: 44.14%] [G loss: 0.655450]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/201 [00:01<00:20,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [D loss: 0.723554, acc.: 32.03%] [G loss: 0.887138]\n",
      "4 [D loss: 0.686885, acc.: 50.00%] [G loss: 0.951322]\n",
      "5 [D loss: 0.730200, acc.: 39.84%] [G loss: 0.795471]\n",
      "6 [D loss: 0.689810, acc.: 51.56%] [G loss: 0.808690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 11/201 [00:01<00:15, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [D loss: 0.707817, acc.: 35.16%] [G loss: 0.718341]\n",
      "8 [D loss: 0.690032, acc.: 49.22%] [G loss: 0.724760]\n",
      "9 [D loss: 0.690305, acc.: 42.97%] [G loss: 0.725031]\n",
      "10 [D loss: 0.699105, acc.: 42.58%] [G loss: 0.725312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 15/201 [00:01<00:13, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 [D loss: 0.631659, acc.: 78.91%] [G loss: 0.848520]\n",
      "12 [D loss: 0.742673, acc.: 34.77%] [G loss: 0.677510]\n",
      "13 [D loss: 0.724618, acc.: 33.20%] [G loss: 0.740743]\n",
      "14 [D loss: 0.598308, acc.: 85.94%] [G loss: 0.950827]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/201 [00:01<00:12, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 [D loss: 0.748309, acc.: 35.55%] [G loss: 0.643942]\n",
      "16 [D loss: 0.821484, acc.: 28.12%] [G loss: 0.584143]\n",
      "17 [D loss: 0.676677, acc.: 59.77%] [G loss: 0.840448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/201 [00:01<00:12, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 [D loss: 0.610853, acc.: 83.59%] [G loss: 0.938941]\n",
      "19 [D loss: 0.650022, acc.: 63.28%] [G loss: 0.887446]\n",
      "20 [D loss: 0.756313, acc.: 29.30%] [G loss: 0.759600]\n",
      "21 [D loss: 0.728475, acc.: 33.98%] [G loss: 0.778566]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 25/201 [00:02<00:11, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 [D loss: 0.636214, acc.: 75.39%] [G loss: 0.886067]\n",
      "23 [D loss: 0.701726, acc.: 48.05%] [G loss: 0.729937]\n",
      "24 [D loss: 0.692845, acc.: 39.06%] [G loss: 0.725504]\n",
      "25 [D loss: 0.641558, acc.: 67.97%] [G loss: 0.878462]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/201 [00:02<00:11, 15.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 [D loss: 0.724304, acc.: 32.81%] [G loss: 0.764726]\n",
      "27 [D loss: 0.604908, acc.: 83.98%] [G loss: 0.912407]\n",
      "28 [D loss: 0.685659, acc.: 40.23%] [G loss: 0.705084]\n",
      "29 [D loss: 0.784759, acc.: 26.56%] [G loss: 0.616831]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/201 [00:02<00:10, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 [D loss: 0.680897, acc.: 48.44%] [G loss: 0.784109]\n",
      "31 [D loss: 0.488568, acc.: 88.28%] [G loss: 1.022120]\n",
      "32 [D loss: 0.517986, acc.: 71.88%] [G loss: 0.984776]\n",
      "33 [D loss: 0.773452, acc.: 37.89%] [G loss: 0.677296]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/201 [00:02<00:10, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 [D loss: 0.845428, acc.: 28.91%] [G loss: 0.568926]\n",
      "35 [D loss: 0.688814, acc.: 51.56%] [G loss: 0.843009]\n",
      "36 [D loss: 0.638633, acc.: 62.89%] [G loss: 0.920435]\n",
      "37 [D loss: 0.684682, acc.: 46.88%] [G loss: 0.878682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/201 [00:03<00:10, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 [D loss: 0.742228, acc.: 33.20%] [G loss: 0.801381]\n",
      "39 [D loss: 0.747093, acc.: 33.98%] [G loss: 0.878402]\n",
      "40 [D loss: 0.605564, acc.: 76.56%] [G loss: 1.110654]\n",
      "41 [D loss: 0.517402, acc.: 88.67%] [G loss: 1.188590]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 45/201 [00:03<00:09, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 [D loss: 0.622090, acc.: 64.06%] [G loss: 0.839116]\n",
      "43 [D loss: 0.687085, acc.: 52.34%] [G loss: 0.777982]\n",
      "44 [D loss: 0.699964, acc.: 39.45%] [G loss: 0.749893]\n",
      "45 [D loss: 0.646823, acc.: 59.38%] [G loss: 0.811863]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/201 [00:03<00:09, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 [D loss: 0.545613, acc.: 80.08%] [G loss: 1.006777]\n",
      "47 [D loss: 0.562644, acc.: 74.61%] [G loss: 1.045896]\n",
      "48 [D loss: 0.748366, acc.: 50.39%] [G loss: 0.884654]\n",
      "49 [D loss: 0.733166, acc.: 38.28%] [G loss: 0.893640]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/201 [00:03<00:09, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 [D loss: 0.684397, acc.: 48.05%] [G loss: 0.911950]\n",
      "51 [D loss: 0.673821, acc.: 49.22%] [G loss: 0.949331]\n",
      "52 [D loss: 0.682803, acc.: 50.00%] [G loss: 0.892081]\n",
      "53 [D loss: 0.633063, acc.: 64.84%] [G loss: 1.007781]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/201 [00:04<00:10, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 [D loss: 0.597956, acc.: 72.27%] [G loss: 0.971366]\n",
      "55 [D loss: 0.689976, acc.: 60.94%] [G loss: 0.909638]\n",
      "56 [D loss: 0.755158, acc.: 47.66%] [G loss: 0.840833]\n",
      "57 [D loss: 0.721160, acc.: 41.41%] [G loss: 0.816230]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/201 [00:04<00:09, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 [D loss: 0.710852, acc.: 41.02%] [G loss: 0.876071]\n",
      "59 [D loss: 0.722174, acc.: 37.89%] [G loss: 0.795401]\n",
      "60 [D loss: 0.678059, acc.: 51.17%] [G loss: 0.851614]\n",
      "61 [D loss: 0.700930, acc.: 44.14%] [G loss: 0.809518]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 65/201 [00:04<00:09, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 [D loss: 0.697455, acc.: 52.73%] [G loss: 0.880072]\n",
      "63 [D loss: 0.670013, acc.: 54.30%] [G loss: 0.881521]\n",
      "64 [D loss: 0.672341, acc.: 53.52%] [G loss: 0.852372]\n",
      "65 [D loss: 0.688349, acc.: 42.19%] [G loss: 0.767715]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/201 [00:05<00:08, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 [D loss: 0.673236, acc.: 50.39%] [G loss: 0.785096]\n",
      "67 [D loss: 0.662382, acc.: 58.59%] [G loss: 0.802408]\n",
      "68 [D loss: 0.671653, acc.: 53.12%] [G loss: 0.758970]\n",
      "69 [D loss: 0.678161, acc.: 50.00%] [G loss: 0.772674]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/201 [00:05<00:08, 15.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 [D loss: 0.670603, acc.: 55.47%] [G loss: 0.800789]\n",
      "71 [D loss: 0.671375, acc.: 45.31%] [G loss: 0.751903]\n",
      "72 [D loss: 0.681129, acc.: 45.70%] [G loss: 0.755616]\n",
      "73 [D loss: 0.666789, acc.: 52.34%] [G loss: 0.776031]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 77/201 [00:05<00:08, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 [D loss: 0.662781, acc.: 54.30%] [G loss: 0.777716]\n",
      "75 [D loss: 0.673832, acc.: 46.09%] [G loss: 0.755191]\n",
      "76 [D loss: 0.664220, acc.: 57.81%] [G loss: 0.774768]\n",
      "77 [D loss: 0.660048, acc.: 52.34%] [G loss: 0.773231]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/201 [00:05<00:07, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 [D loss: 0.675459, acc.: 53.52%] [G loss: 0.759155]\n",
      "79 [D loss: 0.677063, acc.: 54.69%] [G loss: 0.761785]\n",
      "80 [D loss: 0.666177, acc.: 54.30%] [G loss: 0.791037]\n",
      "81 [D loss: 0.648826, acc.: 56.25%] [G loss: 0.802469]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 85/201 [00:06<00:07, 15.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 [D loss: 0.667839, acc.: 45.70%] [G loss: 0.752686]\n",
      "83 [D loss: 0.677281, acc.: 55.86%] [G loss: 0.792059]\n",
      "84 [D loss: 0.645253, acc.: 60.94%] [G loss: 0.804177]\n",
      "85 [D loss: 0.679732, acc.: 54.30%] [G loss: 0.760794]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 89/201 [00:06<00:07, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 [D loss: 0.684020, acc.: 51.56%] [G loss: 0.811780]\n",
      "87 [D loss: 0.641267, acc.: 59.77%] [G loss: 0.870217]\n",
      "88 [D loss: 0.656589, acc.: 56.64%] [G loss: 0.793731]\n",
      "89 [D loss: 0.655231, acc.: 61.33%] [G loss: 0.778803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 93/201 [00:06<00:07, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 [D loss: 0.648248, acc.: 59.77%] [G loss: 0.800200]\n",
      "91 [D loss: 0.635786, acc.: 64.45%] [G loss: 0.797188]\n",
      "92 [D loss: 0.663567, acc.: 51.56%] [G loss: 0.784666]\n",
      "93 [D loss: 0.663212, acc.: 56.25%] [G loss: 0.866105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 97/201 [00:06<00:06, 15.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 [D loss: 0.636874, acc.: 62.11%] [G loss: 0.884161]\n",
      "95 [D loss: 0.631512, acc.: 69.53%] [G loss: 0.898002]\n",
      "96 [D loss: 0.658940, acc.: 55.47%] [G loss: 0.810010]\n",
      "97 [D loss: 0.661417, acc.: 53.12%] [G loss: 0.852796]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/201 [00:07<00:06, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 [D loss: 0.638799, acc.: 66.02%] [G loss: 0.853503]\n",
      "99 [D loss: 0.615267, acc.: 71.88%] [G loss: 0.891819]\n",
      "100 [D loss: 0.653688, acc.: 56.64%] [G loss: 0.866009]\n",
      "generated_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 105/201 [00:07<00:06, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 [D loss: 0.666099, acc.: 50.39%] [G loss: 0.842007]\n",
      "102 [D loss: 0.651683, acc.: 58.98%] [G loss: 0.923288]\n",
      "103 [D loss: 0.646693, acc.: 62.50%] [G loss: 0.858193]\n",
      "104 [D loss: 0.659455, acc.: 58.98%] [G loss: 0.865092]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 109/201 [00:07<00:05, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 [D loss: 0.645711, acc.: 59.38%] [G loss: 0.880491]\n",
      "106 [D loss: 0.653809, acc.: 55.08%] [G loss: 0.818559]\n",
      "107 [D loss: 0.678842, acc.: 43.75%] [G loss: 0.767874]\n",
      "108 [D loss: 0.646079, acc.: 58.20%] [G loss: 0.876584]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 113/201 [00:07<00:05, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 [D loss: 0.666158, acc.: 51.56%] [G loss: 0.835043]\n",
      "110 [D loss: 0.640382, acc.: 59.38%] [G loss: 0.832070]\n",
      "111 [D loss: 0.643277, acc.: 60.94%] [G loss: 0.845614]\n",
      "112 [D loss: 0.669900, acc.: 57.03%] [G loss: 0.820596]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 117/201 [00:08<00:05, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 [D loss: 0.656420, acc.: 57.03%] [G loss: 0.836345]\n",
      "114 [D loss: 0.641564, acc.: 57.42%] [G loss: 0.876468]\n",
      "115 [D loss: 0.646709, acc.: 59.38%] [G loss: 0.825197]\n",
      "116 [D loss: 0.651036, acc.: 54.69%] [G loss: 0.777496]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/201 [00:08<00:05, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 [D loss: 0.652030, acc.: 58.59%] [G loss: 0.793402]\n",
      "118 [D loss: 0.649176, acc.: 59.38%] [G loss: 0.811079]\n",
      "119 [D loss: 0.649228, acc.: 54.69%] [G loss: 0.807060]\n",
      "120 [D loss: 0.631465, acc.: 57.81%] [G loss: 0.873953]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 125/201 [00:08<00:04, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 [D loss: 0.642788, acc.: 54.30%] [G loss: 0.842716]\n",
      "122 [D loss: 0.633139, acc.: 61.72%] [G loss: 0.860812]\n",
      "123 [D loss: 0.666036, acc.: 56.25%] [G loss: 0.833639]\n",
      "124 [D loss: 0.637599, acc.: 57.42%] [G loss: 0.924634]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 129/201 [00:09<00:04, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 [D loss: 0.643670, acc.: 58.59%] [G loss: 0.840004]\n",
      "126 [D loss: 0.666960, acc.: 49.22%] [G loss: 0.773053]\n",
      "127 [D loss: 0.638831, acc.: 59.77%] [G loss: 0.855623]\n",
      "128 [D loss: 0.630438, acc.: 62.11%] [G loss: 0.862262]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 131/201 [00:09<00:04, 15.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 [D loss: 0.641727, acc.: 61.33%] [G loss: 0.807410]\n",
      "130 [D loss: 0.647421, acc.: 56.64%] [G loss: 0.860150]\n",
      "131 [D loss: 0.637578, acc.: 62.11%] [G loss: 0.880380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 135/201 [00:09<00:04, 15.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 [D loss: 0.635053, acc.: 63.67%] [G loss: 0.867916]\n",
      "133 [D loss: 0.642439, acc.: 56.25%] [G loss: 0.792550]\n",
      "134 [D loss: 0.638722, acc.: 62.11%] [G loss: 0.829996]\n",
      "135 [D loss: 0.650501, acc.: 54.30%] [G loss: 0.810637]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 139/201 [00:09<00:04, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 [D loss: 0.642949, acc.: 60.55%] [G loss: 0.825194]\n",
      "137 [D loss: 0.633457, acc.: 60.16%] [G loss: 0.918275]\n",
      "138 [D loss: 0.637209, acc.: 61.72%] [G loss: 0.876791]\n",
      "139 [D loss: 0.633082, acc.: 61.72%] [G loss: 0.847758]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 143/201 [00:09<00:03, 14.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 [D loss: 0.673803, acc.: 50.39%] [G loss: 0.753332]\n",
      "141 [D loss: 0.652552, acc.: 55.08%] [G loss: 0.834769]\n",
      "142 [D loss: 0.609212, acc.: 71.09%] [G loss: 0.917820]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 147/201 [00:10<00:03, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 [D loss: 0.585832, acc.: 72.27%] [G loss: 0.918271]\n",
      "144 [D loss: 0.700710, acc.: 44.14%] [G loss: 0.732573]\n",
      "145 [D loss: 0.648752, acc.: 57.03%] [G loss: 0.886211]\n",
      "146 [D loss: 0.631603, acc.: 61.33%] [G loss: 0.965210]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 151/201 [00:10<00:03, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 [D loss: 0.644220, acc.: 61.72%] [G loss: 0.881742]\n",
      "148 [D loss: 0.620618, acc.: 63.28%] [G loss: 0.864807]\n",
      "149 [D loss: 0.630044, acc.: 61.72%] [G loss: 0.887240]\n",
      "150 [D loss: 0.627703, acc.: 63.28%] [G loss: 0.853771]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 155/201 [00:10<00:02, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 [D loss: 0.668791, acc.: 53.52%] [G loss: 0.834410]\n",
      "152 [D loss: 0.611434, acc.: 61.33%] [G loss: 0.921129]\n",
      "153 [D loss: 0.634519, acc.: 59.77%] [G loss: 0.854780]\n",
      "154 [D loss: 0.642557, acc.: 53.91%] [G loss: 0.862049]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 159/201 [00:10<00:02, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 [D loss: 0.655550, acc.: 58.20%] [G loss: 0.857191]\n",
      "156 [D loss: 0.622134, acc.: 64.45%] [G loss: 0.904369]\n",
      "157 [D loss: 0.619334, acc.: 66.02%] [G loss: 0.884082]\n",
      "158 [D loss: 0.628977, acc.: 63.28%] [G loss: 0.854065]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 163/201 [00:11<00:02, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159 [D loss: 0.625271, acc.: 60.55%] [G loss: 0.915155]\n",
      "160 [D loss: 0.629663, acc.: 59.77%] [G loss: 0.901985]\n",
      "161 [D loss: 0.654066, acc.: 49.22%] [G loss: 0.845741]\n",
      "162 [D loss: 0.617537, acc.: 65.23%] [G loss: 0.928255]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 167/201 [00:11<00:02, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 [D loss: 0.627255, acc.: 65.62%] [G loss: 0.837423]\n",
      "164 [D loss: 0.619008, acc.: 59.77%] [G loss: 0.889656]\n",
      "165 [D loss: 0.624287, acc.: 62.50%] [G loss: 0.928081]\n",
      "166 [D loss: 0.621571, acc.: 60.94%] [G loss: 0.963335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 171/201 [00:11<00:01, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167 [D loss: 0.614337, acc.: 67.97%] [G loss: 0.873778]\n",
      "168 [D loss: 0.631943, acc.: 61.33%] [G loss: 0.901347]\n",
      "169 [D loss: 0.630981, acc.: 60.94%] [G loss: 0.866399]\n",
      "170 [D loss: 0.608251, acc.: 66.02%] [G loss: 0.855200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 175/201 [00:12<00:01, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171 [D loss: 0.616137, acc.: 64.06%] [G loss: 0.882089]\n",
      "172 [D loss: 0.638764, acc.: 59.38%] [G loss: 0.906505]\n",
      "173 [D loss: 0.634071, acc.: 60.94%] [G loss: 0.883332]\n",
      "174 [D loss: 0.613683, acc.: 61.72%] [G loss: 0.965842]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/201 [00:12<00:01, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 [D loss: 0.619862, acc.: 59.38%] [G loss: 0.901156]\n",
      "176 [D loss: 0.625921, acc.: 62.11%] [G loss: 0.861191]\n",
      "177 [D loss: 0.634482, acc.: 60.55%] [G loss: 0.858311]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/201 [00:12<00:01, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 [D loss: 0.610101, acc.: 64.06%] [G loss: 0.872502]\n",
      "179 [D loss: 0.625674, acc.: 60.55%] [G loss: 0.905137]\n",
      "180 [D loss: 0.626871, acc.: 62.89%] [G loss: 0.881574]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 185/201 [00:12<00:01, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 [D loss: 0.621699, acc.: 63.28%] [G loss: 0.852086]\n",
      "182 [D loss: 0.620817, acc.: 63.67%] [G loss: 0.896311]\n",
      "183 [D loss: 0.585868, acc.: 64.84%] [G loss: 0.935561]\n",
      "184 [D loss: 0.610238, acc.: 65.23%] [G loss: 0.875845]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 189/201 [00:12<00:00, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 [D loss: 0.620626, acc.: 62.89%] [G loss: 0.904199]\n",
      "186 [D loss: 0.621455, acc.: 62.89%] [G loss: 0.867477]\n",
      "187 [D loss: 0.607304, acc.: 63.67%] [G loss: 0.905859]\n",
      "188 [D loss: 0.597267, acc.: 64.45%] [G loss: 0.951865]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 193/201 [00:13<00:00, 15.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 [D loss: 0.622227, acc.: 62.11%] [G loss: 0.895168]\n",
      "190 [D loss: 0.621200, acc.: 62.11%] [G loss: 0.871956]\n",
      "191 [D loss: 0.604076, acc.: 64.45%] [G loss: 0.847970]\n",
      "192 [D loss: 0.601647, acc.: 64.45%] [G loss: 0.908888]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 197/201 [00:13<00:00, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193 [D loss: 0.599213, acc.: 64.45%] [G loss: 0.939804]\n",
      "194 [D loss: 0.595883, acc.: 63.28%] [G loss: 0.898727]\n",
      "195 [D loss: 0.596841, acc.: 65.23%] [G loss: 0.925748]\n",
      "196 [D loss: 0.633918, acc.: 58.20%] [G loss: 0.908294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:13<00:00, 14.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197 [D loss: 0.610397, acc.: 60.94%] [G loss: 0.952700]\n",
      "198 [D loss: 0.601393, acc.: 64.06%] [G loss: 0.904418]\n",
      "199 [D loss: 0.613972, acc.: 64.06%] [G loss: 0.877581]\n",
      "200 [D loss: 0.604303, acc.: 63.67%] [G loss: 0.965180]\n",
      "generated_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the GAN model chosen: Vanilla GAN, CGAN, DCGAN, etc.\n",
    "synthesizer = model(gan_args)\n",
    "synthesizer.train(data = fraud_w_classes, train_arguments = train_args, num_cols = num_cols, cat_cols = cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDjYWJPyl4fc",
    "outputId": "8a5c7afb-74ee-44ee-8902-048250d04061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(128, 32)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, 128)                4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (128, 256)                33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, 512)                131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (128, 31)                 15903     \n",
      "=================================================================\n",
      "Total params: 184,735\n",
      "Trainable params: 184,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generator description\n",
    "synthesizer.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zyfNK8Gl4fd",
    "outputId": "634297a1-dbeb-4fd0-fe52-24b181711336",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(128, 31)]               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (128, 512)                16384     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (128, 512)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (128, 256)                131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (128, 256)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (128, 128)                32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (128, 1)                  129       \n",
      "=================================================================\n",
      "Total params: 180,737\n",
      "Trainable params: 0\n",
      "Non-trainable params: 180,737\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Discriminator description\n",
    "synthesizer.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "C3cs_LKEl4fd",
    "outputId": "bdb0af49-7e29-480e-cb83-56ad2f192ae0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# You can easily save the trained generator and loaded it afterwards\n",
    "if not os.path.exists(\"./saved/gan\"):\n",
    "    os.makedirs(\"./saved/gan\")\n",
    "synthesizer.save(path=\"./saved/gan/generator_fraud.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5mvCYNH5l4fd"
   },
   "outputs": [],
   "source": [
    "models = {'GAN': ['GAN', False, synthesizer.generator]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5wl54IVkl4fe",
    "outputId": "7f131092-2e97-4a95-eb93-d97b2f991321",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup parameters visualization parameters\n",
    "seed = 17\n",
    "test_size = 492 # number of fraud cases\n",
    "noise_dim = 32\n",
    "\n",
    "random.seed(seed)\n",
    "z = random.normal(size=(test_size, noise_dim))\n",
    "real_processed = synthesizer.processor.transform(fraud_w_classes)\n",
    "real_samples = synthesizer.get_data_batch(real_processed, batch_size)\n",
    "class_labels = ['Class_1','Class_2']\n",
    "real_samples = DataFrame(real_samples, columns=num_cols+class_labels)\n",
    "labels = fraud_w_classes['Class']\n",
    "\n",
    "model_names = ['GAN']\n",
    "colors = ['deepskyblue','blue']\n",
    "markers = ['o','^']\n",
    "\n",
    "col1, col2 = 'V17', 'V10'\n",
    "\n",
    "base_dir = 'cache/'\n",
    "\n",
    "# Actual fraud data visualization\n",
    "model_steps = [ 0, 100, 200]\n",
    "rows = len(model_steps)\n",
    "columns = 1 + len(models)\n",
    "\n",
    "axarr = [[]]*len(model_steps)\n",
    "\n",
    "fig = plt.figure(figsize=(14,rows*3))\n",
    "\n",
    "# Go through each of the 3 model_step values -> 0, 100, 200\n",
    "for model_step_ix, model_step in enumerate(model_steps):\n",
    "    axarr[model_step_ix] = plt.subplot(rows, columns, model_step_ix*columns + 1)\n",
    "\n",
    "    # Plot 'Class 1' and 'Class 2' samples taken from the original data, in a random shuffled fashion\n",
    "    for group, color, marker, label in zip(real_samples.groupby('Class_1'), colors, markers, class_labels ):\n",
    "        plt.scatter( group[1][[col1]], group[1][[col2]],\n",
    "                         label=label, marker=marker, edgecolors=color, facecolors='none' )\n",
    "\n",
    "    plt.title('Actual Fraud Data')\n",
    "    plt.ylabel(col2) # Only add y label to left plot\n",
    "    plt.xlabel(col1)\n",
    "    xlims, ylims = axarr[model_step_ix].get_xlim(), axarr[model_step_ix].get_ylim()\n",
    "\n",
    "    if model_step_ix == 0:\n",
    "        legend = plt.legend()\n",
    "        legend.get_frame().set_facecolor('white')\n",
    "\n",
    "    # Go through all the GAN models listed in 'model_names' and defined in 'models'\n",
    "    for i, model_name in enumerate( model_names[:] ):\n",
    "\n",
    "        [model_name, with_class, generator_model] = models[model_name]\n",
    "\n",
    "        generator_model.load_weights( base_dir + '_generator_model_weights_step_'+str(model_step)+'.h5')\n",
    "\n",
    "        ax = plt.subplot(rows, columns, model_step_ix*columns + 1 + (i+1) )\n",
    "\n",
    "        if with_class:\n",
    "            g_z = generator_model([z, labels])\n",
    "            gen_samples = DataFrame(g_z, columns=num_cols+class_labels)\n",
    "            for group, color, marker, label in zip( gen_samples.groupby('Class_1'), colors, markers, class_labels ):\n",
    "                plt.scatter( group[1][[col1]], group[1][[col2]],\n",
    "                                 label=label, marker=marker, edgecolors=color, facecolors='none' )\n",
    "        else:\n",
    "            g_z = generator_model(z)\n",
    "            gen_samples = DataFrame(g_z, columns=num_cols+class_labels)\n",
    "            gen_samples.to_csv('../../data/Generated_sample.csv')\n",
    "            plt.scatter( gen_samples[[col1]], gen_samples[[col2]],\n",
    "                             label=class_labels[0], marker=markers[0], edgecolors=colors[0], facecolors='none' )\n",
    "        plt.title(model_name)\n",
    "        plt.xlabel(col1)\n",
    "        ax.set_xlim(xlims), ax.set_ylim(ylims)\n",
    "\n",
    "plt.suptitle('Comparison of GAN outputs', size=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0.075,0,1,0.95])\n",
    "\n",
    "# Adding text labels for training steps\n",
    "vpositions = array([ i._position.bounds[1] for i in axarr ])\n",
    "vpositions += ((vpositions[0] - vpositions[1]) * 0.35 )\n",
    "for model_step_ix, model_step in enumerate( model_steps ):\n",
    "    fig.text( 0.05, vpositions[model_step_ix], 'training\\nstep\\n'+str(model_step), ha='center', va='center', size=12)\n",
    "\n",
    "if not os.path.exists(\"./img\"):\n",
    "    os.makedirs(\"./img\")\n",
    "plt.savefig('img/Comparison_of_GAN_outputs.png', dpi=100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "gan_example.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e9b94595181d602aedee98e3f77f0c817ffdebb9c945d905c1f334bc0562225d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ydata_synth': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
