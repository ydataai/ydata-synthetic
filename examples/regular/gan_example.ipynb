{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "name": "gan_example.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# The Credit Card Fraud Dataset - Synthesizing the Minority Class\n",
    "\n",
    "In this notebook a practical exercise is presented to showcase the usage of the YData Synthetic library along with\n",
    "GANs to synthesize tabular data.\n",
    "For the purpose of this exercise, dataset of credit card fraud from Kaggle is used, that can be found here:\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ],
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "AnCU8-Mal4fV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Note: You can select between running the Notebook on \"CPU\" or \"GPU\"\n",
    "# Click \"Runtime > Change Runtime time\" and set \"GPU\""
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "j0CX0r65l4fY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Install ydata-synthetic lib\n",
    "# ! pip install ydata-synthetic"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "x0u2qegKl4fY",
    "outputId": "51b00474-09de-4e9a-dbf9-9535f056fbd0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import os\n",
    "\n",
    "import sklearn.cluster as cluster\n",
    "\n",
    "from ydata_synthetic.synthesizers.regular import VanilllaGAN\n",
    "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
    "from ydata_synthetic.preprocessing.regular.credit_fraud import *\n",
    "\n",
    "model = VanilllaGAN"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "oX2OK2fbl4fZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Read the original data and have it preprocessed\n",
    "data = pd.read_csv('./data/creditcard.csv', index_col=[0])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/creditcard.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bf6d782ba361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read the original data and have it preprocessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/creditcard.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ydata_synth/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/creditcard.csv'"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "P1Rcz4RPl4fZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Extract list of columns\n",
    "data_cols = list(data.columns[ data.columns != 'Class' ])\n",
    "\n",
    "print('Dataset columns: {}'.format(data_cols))\n",
    "sorted_cols = ['V14', 'V4', 'V10', 'V17', 'V12', 'V26', 'Amount', 'V21', 'V8', 'V11', 'V7', 'V28', 'V19', 'V3', 'V22', 'V6', 'V20', 'V27', 'V16', 'V13', 'V25', 'V24', 'V18', 'V2', 'V1', 'V5', 'V15', 'V9', 'V23', 'Class']\n",
    "processed_data = data[ sorted_cols ].copy()"
   ],
   "outputs": [],
   "metadata": {
    "id": "ceNe1Ofbl4fZ",
    "outputId": "f8f9fece-e7d3-454f-d4c9-d6cd116ca68a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Before training the GAN do not forget to apply the required data transformations\n",
    "# To ease here we've applied a PowerTransformation - make data distribution more Gaussian-like.\n",
    "_, data, _ = transformations(data)\n",
    "\n",
    "# For the purpose of this example we will only synthesize the minority class\n",
    "# train_data contains 492 rows which had 'Class' value as 1 (which were very few)\n",
    "train_data = data.loc[ data['Class']==1 ].copy()\n",
    "\n",
    "print(\"Dataset info: Number of records - {} Number of variables - {}\".format(train_data.shape[0], train_data.shape[1]))\n",
    "\n",
    "# We define a K-means clustering method using sklearn, and declare that\n",
    "# we want 2 clusters. We then apply this algorithm (fit_predict) to our train_data\n",
    "# We essentially get an array of 492 rows ('labels') having values either 0 or 1 for the 2 clustered classes.\n",
    "algorithm = cluster.KMeans\n",
    "args, kwds = (), {'n_clusters':2, 'random_state':0}\n",
    "labels = algorithm(*args, **kwds).fit_predict(train_data[ data_cols ])\n",
    "\n",
    "# Get the count of both classes\n",
    "print( pd.DataFrame( [ [np.sum(labels==i)] for i in np.unique(labels) ], columns=['count'], index=np.unique(labels) ) )\n",
    "\n",
    "# Assign the k-means clustered classes' labels to the a seperate copy of train data 'fraud_w_classes'\n",
    "fraud_w_classes = train_data.copy()\n",
    "fraud_w_classes['Class'] = labels"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3o4V8-ypl4fa",
    "outputId": "39fabdb7-b3e4-492f-85f0-cd6232b45609",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GAN training\n",
    "\n",
    "Below you can try to train your own generators using the available GANs architectures. You can train it either with labels (created using KMeans) or with no labels at all. \n",
    "\n",
    "Remember that for this exercise in particular we've decided to synthesize only the minority class from the Credit Fraud dataset."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "3ezlIjKbl4fb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define the GAN and training parameters\n",
    "noise_dim = 32\n",
    "dim = 128\n",
    "batch_size = 128\n",
    "\n",
    "log_step = 100\n",
    "epochs = 200+1\n",
    "learning_rate = 5e-4\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.9\n",
    "models_dir = './cache'\n",
    "\n",
    "train_sample = fraud_w_classes.copy().reset_index(drop=True)\n",
    "print(\"train_sample.columns:\")\n",
    "print(train_sample.columns)\n",
    "\n",
    "# There's only 1 class, so essentially rename the 'Class' to 'Class_1',\n",
    "# which tells weather a sample data is of class 1 or not.\n",
    "train_sample = pd.get_dummies(train_sample, columns=['Class'], prefix='Class', drop_first=True)\n",
    "\n",
    "# 'Class_1' label\n",
    "label_cols = [ i for i in train_sample.columns if 'Class' in i ]\n",
    "\n",
    "# All columns except 'Class_1'\n",
    "data_cols = [ i for i in train_sample.columns if i not in label_cols ]\n",
    "\n",
    "# Scale down the data, and rename it to 'train_no_label'\n",
    "train_sample[ data_cols ] = train_sample[ data_cols ] / 10 # scale to random noise size, one less thing to learn\n",
    "train_no_label = train_sample[ data_cols ]"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7FMDs5eql4fb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Setting the GAN model parameters and the training step parameters\n",
    "gan_args = ModelParameters(batch_size=batch_size,\n",
    "                           lr=learning_rate,\n",
    "                           betas=(beta_1, beta_2),\n",
    "                           noise_dim=noise_dim,\n",
    "                           n_cols=train_sample.shape[1],\n",
    "                           layers_dim=dim)\n",
    "\n",
    "train_args = TrainParameters(epochs=epochs,\n",
    "                             sample_interval=log_step)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training the GAN model chosen: Vanilla GAN, CGAN, DCGAN, etc.\n",
    "synthesizer = model(gan_args)\n",
    "synthesizer.train(train_sample, train_args)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qgMDmyall4fc",
    "outputId": "ae669bdf-01b6-49d9-a254-cc0776508f7b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generator description\n",
    "synthesizer.generator.summary()"
   ],
   "outputs": [],
   "metadata": {
    "id": "tDjYWJPyl4fc",
    "outputId": "8a5c7afb-74ee-44ee-8902-048250d04061",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Discriminator description\n",
    "synthesizer.discriminator.summary()"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "9zyfNK8Gl4fd",
    "outputId": "634297a1-dbeb-4fd0-fe52-24b181711336",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# You can easily save the trained generator and loaded it afterwards\n",
    "if not os.path.exists(\"./saved/gan\"):\n",
    "    os.makedirs(\"./saved/gan\")\n",
    "synthesizer.save(path=\"./saved/gan/generator_fraud.pkl\")"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "C3cs_LKEl4fd",
    "outputId": "bdb0af49-7e29-480e-cb83-56ad2f192ae0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models = {'GAN': ['GAN', False, synthesizer.generator]}"
   ],
   "outputs": [],
   "metadata": {
    "id": "5mvCYNH5l4fd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Setup parameters visualization parameters\n",
    "seed = 17\n",
    "test_size = 492 # number of fraud cases\n",
    "noise_dim = 32\n",
    "\n",
    "np.random.seed(seed)\n",
    "z = np.random.normal(size=(test_size, noise_dim))\n",
    "real = synthesizer.get_data_batch(train=train_sample, batch_size=test_size, seed=seed)\n",
    "real_samples = pd.DataFrame(real, columns=data_cols+label_cols)\n",
    "labels = fraud_w_classes['Class']\n",
    "\n",
    "model_names = ['GAN']\n",
    "colors = ['deepskyblue','blue']\n",
    "markers = ['o','^']\n",
    "class_labels = ['Class 1','Class 2']\n",
    "\n",
    "col1, col2 = 'V17', 'V10'\n",
    "\n",
    "base_dir = 'cache/'\n",
    "\n",
    "# Actual fraud data visualization\n",
    "model_steps = [ 0, 100, 200]\n",
    "rows = len(model_steps)\n",
    "columns = 1 + len(models)\n",
    "\n",
    "axarr = [[]]*len(model_steps)\n",
    "\n",
    "fig = plt.figure(figsize=(14,rows*3))\n",
    "\n",
    "# Go through each of the 3 model_step values -> 0, 100, 200\n",
    "for model_step_ix, model_step in enumerate(model_steps):        \n",
    "    axarr[model_step_ix] = plt.subplot(rows, columns, model_step_ix*columns + 1)\n",
    "\n",
    "    # Plot 'Class 1' and 'Class 2' samples taken from the original data, in a random shuffled fashion\n",
    "    for group, color, marker, label in zip(real_samples.groupby('Class_1'), colors, markers, class_labels ):\n",
    "        plt.scatter( group[1][[col1]], group[1][[col2]], \n",
    "                         label=label, marker=marker, edgecolors=color, facecolors='none' )\n",
    "    \n",
    "    plt.title('Actual Fraud Data')\n",
    "    plt.ylabel(col2) # Only add y label to left plot\n",
    "    plt.xlabel(col1)\n",
    "    xlims, ylims = axarr[model_step_ix].get_xlim(), axarr[model_step_ix].get_ylim()\n",
    "    \n",
    "    if model_step_ix == 0: \n",
    "        legend = plt.legend()\n",
    "        legend.get_frame().set_facecolor('white')\n",
    "\n",
    "    # Go through all the GAN models listed in 'model_names' and defined in 'models'\n",
    "    for i, model_name in enumerate( model_names[:] ):\n",
    "\n",
    "        [model_name, with_class, generator_model] = models[model_name]\n",
    "\n",
    "        generator_model.load_weights( base_dir + '_generator_model_weights_step_'+str(model_step)+'.h5')\n",
    "\n",
    "        ax = plt.subplot(rows, columns, model_step_ix*columns + 1 + (i+1) )\n",
    "\n",
    "        if with_class:\n",
    "            g_z = generator_model.predict([z, labels])\n",
    "            gen_samples = pd.DataFrame(g_z, columns=data_cols+label_cols)\n",
    "            for group, color, marker, label in zip( gen_samples.groupby('Class_1'), colors, markers, class_labels ):\n",
    "                plt.scatter( group[1][[col1]], group[1][[col2]], \n",
    "                                 label=label, marker=marker, edgecolors=color, facecolors='none' )\n",
    "        else:\n",
    "            g_z = generator_model.predict(z)\n",
    "            gen_samples = pd.DataFrame(g_z, columns=data_cols+['label'])\n",
    "            gen_samples.to_csv('../../data/Generated_sample.csv')\n",
    "            plt.scatter( gen_samples[[col1]], gen_samples[[col2]],\n",
    "                             label=class_labels[0], marker=markers[0], edgecolors=colors[0], facecolors='none' )\n",
    "        plt.title(model_name)   \n",
    "        plt.xlabel(col1)\n",
    "        ax.set_xlim(xlims), ax.set_ylim(ylims)\n",
    "\n",
    "plt.suptitle('Comparison of GAN outputs', size=16, fontweight='bold')\n",
    "plt.tight_layout(rect=[0.075,0,1,0.95])\n",
    "\n",
    "# Adding text labels for training steps\n",
    "vpositions = np.array([ i._position.bounds[1] for i in axarr ])\n",
    "vpositions += ((vpositions[0] - vpositions[1]) * 0.35 )\n",
    "for model_step_ix, model_step in enumerate( model_steps ):\n",
    "    fig.text( 0.05, vpositions[model_step_ix], 'training\\nstep\\n'+str(model_step), ha='center', va='center', size=12)\n",
    "\n",
    "if not os.path.exists(\"./img\"):\n",
    "    os.makedirs(\"./img\")\n",
    "plt.savefig('img/Comparison_of_GAN_outputs.png', dpi=100)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5wl54IVkl4fe",
    "outputId": "7f131092-2e97-4a95-eb93-d97b2f991321",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}